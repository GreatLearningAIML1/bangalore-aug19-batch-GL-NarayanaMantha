{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MyfMmMnPJjvn"
   },
   "source": [
    "## Train a simple convnet on the Fashion MNIST dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zjcGOJhcJjvp"
   },
   "source": [
    "In this, we will see how to deal with image data and train a convnet for image classification task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jR0Pl2XjJjvq"
   },
   "source": [
    "### Load the  `fashion_mnist`  dataset\n",
    "\n",
    "** Use keras.datasets to load the dataset **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qr75v_UYJjvs"
   },
   "outputs": [],
   "source": [
    "from keras.datasets import fashion_mnist\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hTI42-0qJjvw"
   },
   "source": [
    "### Find no.of samples are there in training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1166,
     "status": "ok",
     "timestamp": 1582954083372,
     "user": {
      "displayName": "narayana mantha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBG49VVnVWgC0LuOds0cb1i5wiOhLyqmV5zEUmO2Q=s64",
      "userId": "18079235043046323073"
     },
     "user_tz": -330
    },
    "id": "g2sf67VoJjvx",
    "outputId": "a0d7fa24-a996-4b94-dce3-1e99af908c9d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 50,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using shape to find the number of samples in training and test sets\n",
    "x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1134,
     "status": "ok",
     "timestamp": 1582954083373,
     "user": {
      "displayName": "narayana mantha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBG49VVnVWgC0LuOds0cb1i5wiOhLyqmV5zEUmO2Q=s64",
      "userId": "18079235043046323073"
     },
     "user_tz": -330
    },
    "id": "zewyDcBlJjv1",
    "outputId": "5ffa0000-3981-44ad-e80f-44500f01d7f7"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 51,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WytT2eRnJjv4"
   },
   "source": [
    "### Find dimensions of an image in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1111,
     "status": "ok",
     "timestamp": 1582954083377,
     "user": {
      "displayName": "narayana mantha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBG49VVnVWgC0LuOds0cb1i5wiOhLyqmV5zEUmO2Q=s64",
      "userId": "18079235043046323073"
     },
     "user_tz": -330
    },
    "id": "XycQGBSGJjv5",
    "outputId": "50633ee6-fe7e-42d1-e7c2-55cc50c6b581"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28 28\n",
      "28 28\n",
      "(60000,)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape[1], x_train.shape[2])\n",
    "print(x_test.shape[1], x_test.shape[2])\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7MEwELhCV99G"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5jtdZ7RqJjv8"
   },
   "source": [
    "### Convert train and test labels to one hot vectors\n",
    "\n",
    "** check `keras.utils.to_categorical()` **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sAD3q5I6Jjv9"
   },
   "outputs": [],
   "source": [
    "#for training label data\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)   # Converting the target into categorical which is stored as numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mgHSCXy3JjwA"
   },
   "outputs": [],
   "source": [
    "#for testing label data\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)     # Keras converst these into 1-hot coded vectors as these are lables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "da5-DwgrJjwM"
   },
   "source": [
    "### Reshape the data from 28x28 to 28x28x1 to match input dimensions in Conv2D layer in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1070,
     "status": "ok",
     "timestamp": 1582954083388,
     "user": {
      "displayName": "narayana mantha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBG49VVnVWgC0LuOds0cb1i5wiOhLyqmV5zEUmO2Q=s64",
      "userId": "18079235043046323073"
     },
     "user_tz": -330
    },
    "id": "3fUQpMHxJjwE",
    "outputId": "993d055d-2a89-4fa8-ee90-64345da84ac0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 60000\n",
      "Test size: 10000\n",
      "Train dtype: float32\n",
      "Test dtype: float32\n"
     ]
    }
   ],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1).astype('float32')    # 784 = 28 X 28 the size of each image. There are 60000 images for training\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1).astype('float32')\n",
    "\n",
    "print ('Train size:', x_train.shape[0])\n",
    "print ('Test size:', x_test.shape[0])\n",
    "print ('Train dtype:', x_train.dtype)\n",
    "print ('Test dtype:', x_test.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xO5BRBzBJjwD"
   },
   "source": [
    "### Normalize both the train and test image data from 0-255 to 0-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Okwo_SB5JjwI"
   },
   "outputs": [],
   "source": [
    "x_train /= 255                           # Scale the data between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LPGVQ-JJJjwN"
   },
   "outputs": [],
   "source": [
    "x_test /= 255   #scale the data between 0 and 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OFRRTJq8JjwQ"
   },
   "source": [
    "### Import the necessary layers from keras to build the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dWTZYnKSJjwR"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C18AoS7eJjwU"
   },
   "source": [
    "### Build a model \n",
    "\n",
    "** with 2 Conv layers having `32 3x3 filters` in both convolutions with `relu activations` and `flatten` before passing the feature map into 2 fully connected layers (or Dense Layers) having 128 and 10 neurons with `relu` and `softmax` activations respectively. Now, using `categorical_crossentropy` loss with `adam` optimizer train the model with early stopping `patience=5` and no.of `epochs=10`. **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yDkYvmr_aLey"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DORCLgSwJjwV"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 10\n",
    "BATCH_SIZE = 256\n",
    "PATIENCE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 31654,
     "status": "ok",
     "timestamp": 1582954332318,
     "user": {
      "displayName": "narayana mantha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBG49VVnVWgC0LuOds0cb1i5wiOhLyqmV5zEUmO2Q=s64",
      "userId": "18079235043046323073"
     },
     "user_tz": -330
    },
    "id": "sKs6hUDjZXUm",
    "outputId": "e5dac1c4-b898-4198-f4a4-701e5e1fc99d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:29: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 4s 59us/step - loss: 0.4476 - acc: 0.8439 - val_loss: 0.3415 - val_acc: 0.8774\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2858 - acc: 0.8957 - val_loss: 0.2990 - val_acc: 0.8934\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.2353 - acc: 0.9141 - val_loss: 0.2666 - val_acc: 0.9011\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1921 - acc: 0.9289 - val_loss: 0.2480 - val_acc: 0.9105\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.1631 - acc: 0.9407 - val_loss: 0.2793 - val_acc: 0.9055\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.1337 - acc: 0.9515 - val_loss: 0.2571 - val_acc: 0.9151\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.1064 - acc: 0.9616 - val_loss: 0.2622 - val_acc: 0.9166\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0864 - acc: 0.9691 - val_loss: 0.2793 - val_acc: 0.9169\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 3s 49us/step - loss: 0.0662 - acc: 0.9766 - val_loss: 0.3063 - val_acc: 0.9174\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 3s 50us/step - loss: 0.0525 - acc: 0.9819 - val_loss: 0.3127 - val_acc: 0.9151\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2bcf313dd8>"
      ]
     },
     "execution_count": 65,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "    \n",
    "    # Define model\n",
    "    model = Sequential()\n",
    "\n",
    "    # 1st Conv Layer\n",
    "    model.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # 2nd Conv Layer\n",
    "    model.add(Convolution2D(32, 3, 3))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Fully Connected Layer\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128))\n",
    "    model.add(Activation('relu'))\n",
    "\n",
    "    # Prediction Layer\n",
    "    model.add(Dense(10))\n",
    "    model.add(Activation('softmax'))\n",
    "\n",
    "    # Loss and Optimizer\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # Store Training Results\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=PATIENCE, verbose=1, mode='auto')\n",
    "    callback_list = [early_stopping]\n",
    "\n",
    "    # Train the model\n",
    "    model.fit(x_train, y_train, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, \n",
    "              validation_data=(x_test, y_test), callbacks=callback_list)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1507,
     "status": "ok",
     "timestamp": 1582954346892,
     "user": {
      "displayName": "narayana mantha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBG49VVnVWgC0LuOds0cb1i5wiOhLyqmV5zEUmO2Q=s64",
      "userId": "18079235043046323073"
     },
     "user_tz": -330
    },
    "id": "uC0-dNg2bEA_",
    "outputId": "228e58fb-7039-4e36-c0c2-8e49ff973bbb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 60us/step\n",
      "[0.3126581842198968, 0.9151]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(x_test, y_test)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4628,
     "status": "ok",
     "timestamp": 1582954870102,
     "user": {
      "displayName": "narayana mantha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBG49VVnVWgC0LuOds0cb1i5wiOhLyqmV5zEUmO2Q=s64",
      "userId": "18079235043046323073"
     },
     "user_tz": -330
    },
    "id": "CUhzXFGedkqU",
    "outputId": "cdd62e66-46d3-448e-bd65-0900681d5870"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 4s 62us/step\n",
      "[0.03348657704073315, 0.9907]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model.evaluate(x_train, y_train)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ju69vKdIJjwX"
   },
   "source": [
    "### Now, to the above model add `max` pooling layer of `filter size 2x2` and `dropout` layer with `p=0.25` after the 2 conv layers and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L2hAP94vJjwY"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "BATCH_SIZE = 256\n",
    "PATIENCE = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 58330,
     "status": "ok",
     "timestamp": 1582955619373,
     "user": {
      "displayName": "narayana mantha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBG49VVnVWgC0LuOds0cb1i5wiOhLyqmV5zEUmO2Q=s64",
      "userId": "18079235043046323073"
     },
     "user_tz": -330
    },
    "id": "e78E_zJgb0r6",
    "outputId": "ae464900-b4d6-4270-ce09-43ad5ffc46e7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3), input_shape=(28, 28, 1...)`\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: UserWarning: Update your `Conv2D` call to the Keras 2 API: `Conv2D(32, (3, 3))`\n",
      "  \n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:35: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "60000/60000 [==============================] - 4s 60us/step - loss: 0.5165 - acc: 0.8182 - val_loss: 0.3725 - val_acc: 0.8677\n",
      "Epoch 2/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.3201 - acc: 0.8847 - val_loss: 0.3300 - val_acc: 0.8741\n",
      "Epoch 3/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2783 - acc: 0.8997 - val_loss: 0.2783 - val_acc: 0.8994\n",
      "Epoch 4/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2469 - acc: 0.9114 - val_loss: 0.2573 - val_acc: 0.9071\n",
      "Epoch 5/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.2236 - acc: 0.9187 - val_loss: 0.2486 - val_acc: 0.9096\n",
      "Epoch 6/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.2040 - acc: 0.9252 - val_loss: 0.2470 - val_acc: 0.9085\n",
      "Epoch 7/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1868 - acc: 0.9318 - val_loss: 0.2365 - val_acc: 0.9116\n",
      "Epoch 8/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1690 - acc: 0.9377 - val_loss: 0.2295 - val_acc: 0.9181\n",
      "Epoch 9/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.1568 - acc: 0.9417 - val_loss: 0.2223 - val_acc: 0.9217\n",
      "Epoch 10/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1451 - acc: 0.9463 - val_loss: 0.2280 - val_acc: 0.9211\n",
      "Epoch 11/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1309 - acc: 0.9516 - val_loss: 0.2238 - val_acc: 0.9247\n",
      "Epoch 12/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.1229 - acc: 0.9547 - val_loss: 0.2227 - val_acc: 0.9248\n",
      "Epoch 13/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1126 - acc: 0.9587 - val_loss: 0.2450 - val_acc: 0.9186\n",
      "Epoch 14/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.1029 - acc: 0.9615 - val_loss: 0.2342 - val_acc: 0.9234\n",
      "Epoch 15/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0915 - acc: 0.9664 - val_loss: 0.2330 - val_acc: 0.9264\n",
      "Epoch 16/20\n",
      "60000/60000 [==============================] - 3s 47us/step - loss: 0.0866 - acc: 0.9680 - val_loss: 0.2475 - val_acc: 0.9237\n",
      "Epoch 17/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.0767 - acc: 0.9720 - val_loss: 0.2509 - val_acc: 0.9237\n",
      "Epoch 18/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.0735 - acc: 0.9733 - val_loss: 0.2463 - val_acc: 0.9272\n",
      "Epoch 19/20\n",
      "60000/60000 [==============================] - 3s 46us/step - loss: 0.0661 - acc: 0.9758 - val_loss: 0.2666 - val_acc: 0.9268\n",
      "Epoch 20/20\n",
      "60000/60000 [==============================] - 3s 48us/step - loss: 0.0634 - acc: 0.9767 - val_loss: 0.2520 - val_acc: 0.9279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2baacbd748>"
      ]
     },
     "execution_count": 98,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \n",
    "    # Define Model\n",
    "    model2 = Sequential()\n",
    "\n",
    "    # 1st Conv Layer\n",
    "    model2.add(Convolution2D(32, 3, 3, input_shape=(28, 28, 1)))\n",
    "    model2.add(Activation('relu'))\n",
    "\n",
    "    # 2nd Conv Layer\n",
    "    model2.add(Convolution2D(32, 3, 3))\n",
    "    model2.add(Activation('relu'))\n",
    "\n",
    "    # Max Pooling\n",
    "    model2.add(MaxPooling2D(pool_size=(2,2)))\n",
    "    \n",
    "    # Dropout\n",
    "    model2.add(Dropout(0.25))\n",
    "\n",
    "    # Fully Connected Layer\n",
    "    model2.add(Flatten())\n",
    "    model2.add(Dense(128))\n",
    "    model2.add(Activation('relu'))\n",
    "    \n",
    "    # Prediction Layer\n",
    "    model2.add(Dense(10))\n",
    "    model2.add(Activation('softmax'))\n",
    "\n",
    "    # Loss and Optimizer\n",
    "    model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    # Store Training Results\n",
    "    early_stopping = keras.callbacks.EarlyStopping(monitor='val_acc', patience=PATIENCE, verbose=1, mode='auto')\n",
    "    callback_list = [early_stopping]\n",
    "\n",
    "    # Train the model\n",
    "    model2.fit(x_train, y_train, batch_size=BATCH_SIZE, nb_epoch=EPOCHS, \n",
    "              validation_data=(x_test, y_test), callbacks=callback_list)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1658,
     "status": "ok",
     "timestamp": 1582955626784,
     "user": {
      "displayName": "narayana mantha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBG49VVnVWgC0LuOds0cb1i5wiOhLyqmV5zEUmO2Q=s64",
      "userId": "18079235043046323073"
     },
     "user_tz": -330
    },
    "id": "jQXcnj6AcUUl",
    "outputId": "a8cab821-ce17-4c52-8d97-f43a8ac82fc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 58us/step\n",
      "[0.25204551481604576, 0.9279]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model2.evaluate(x_test, y_test)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4843,
     "status": "ok",
     "timestamp": 1582955633093,
     "user": {
      "displayName": "narayana mantha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBG49VVnVWgC0LuOds0cb1i5wiOhLyqmV5zEUmO2Q=s64",
      "userId": "18079235043046323073"
     },
     "user_tz": -330
    },
    "id": "FtR_yG4GdeCt",
    "outputId": "8386c79c-6b04-46ab-a8ec-562ee253bef0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 4s 60us/step\n",
      "[0.02877534565643097, 0.9924833333333334]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model2.evaluate(x_train, y_train)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lGTA3bfEJjwa"
   },
   "source": [
    "### Now, to the above model, lets add Data Augmentation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "F6gX8n5SJjwb"
   },
   "source": [
    "### Import the ImageDataGenrator from keras and fit the training images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cbz4uHBuJjwc"
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# This will do preprocessing and realtime data augmentation:\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=50,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=False,  # randomly flip images\n",
    "    vertical_flip=False)  # randomly flip images\n",
    "\n",
    "# Prepare the generator\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pl-8dOo7Jjwf"
   },
   "source": [
    "#### Showing 5 versions of the first image in training dataset using image datagenerator.flow()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1054,
     "status": "ok",
     "timestamp": 1582954946172,
     "user": {
      "displayName": "narayana mantha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBG49VVnVWgC0LuOds0cb1i5wiOhLyqmV5zEUmO2Q=s64",
      "userId": "18079235043046323073"
     },
     "user_tz": -330
    },
    "id": "DpI1_McYJjwg",
    "outputId": "052e7a27-fc5b-450a-bab4-7d690ecfd21d",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABICAYAAABV5CYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTSQSiQaRm24ikUg0iP8DPiR/R4K6fAIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "gen = datagen.flow(x_train[0:1], batch_size=1)\n",
    "for i in range(1, 6):\n",
    "    plt.subplot(1,5,i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
    "    plt.plot()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dmPl5yE8Jjwm"
   },
   "source": [
    "### Run the above model using fit_generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 802
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 256224,
     "status": "ok",
     "timestamp": 1582955902153,
     "user": {
      "displayName": "narayana mantha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBG49VVnVWgC0LuOds0cb1i5wiOhLyqmV5zEUmO2Q=s64",
      "userId": "18079235043046323073"
     },
     "user_tz": -330
    },
    "id": "44ZnDdJYJjwn",
    "outputId": "ecabe2f8-a9ef-4510-d1c4-0bd89fce3e98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "  3/234 [..............................] - ETA: 13s - loss: 4.4674 - acc: 0.3073"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "  after removing the cwd from sys.path.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:4: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<keras_pre..., validation_data=(array([[[..., callbacks=[<keras.ca..., steps_per_epoch=234, epochs=20)`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234/234 [==============================] - 13s 56ms/step - loss: 1.0870 - acc: 0.6175 - val_loss: 0.4981 - val_acc: 0.8148\n",
      "Epoch 2/20\n",
      "234/234 [==============================] - 13s 54ms/step - loss: 0.7377 - acc: 0.7269 - val_loss: 0.4577 - val_acc: 0.8418\n",
      "Epoch 3/20\n",
      "234/234 [==============================] - 13s 55ms/step - loss: 0.6756 - acc: 0.7486 - val_loss: 0.4193 - val_acc: 0.8481\n",
      "Epoch 4/20\n",
      "234/234 [==============================] - 12s 53ms/step - loss: 0.6374 - acc: 0.7650 - val_loss: 0.4062 - val_acc: 0.8576\n",
      "Epoch 5/20\n",
      "234/234 [==============================] - 13s 53ms/step - loss: 0.6095 - acc: 0.7744 - val_loss: 0.4120 - val_acc: 0.8522\n",
      "Epoch 6/20\n",
      "234/234 [==============================] - 13s 55ms/step - loss: 0.5892 - acc: 0.7834 - val_loss: 0.4080 - val_acc: 0.8534\n",
      "Epoch 7/20\n",
      "234/234 [==============================] - 13s 56ms/step - loss: 0.5680 - acc: 0.7903 - val_loss: 0.4132 - val_acc: 0.8529\n",
      "Epoch 8/20\n",
      "234/234 [==============================] - 13s 56ms/step - loss: 0.5553 - acc: 0.7944 - val_loss: 0.3787 - val_acc: 0.8650\n",
      "Epoch 9/20\n",
      "234/234 [==============================] - 13s 54ms/step - loss: 0.5414 - acc: 0.7999 - val_loss: 0.3922 - val_acc: 0.8578\n",
      "Epoch 10/20\n",
      "234/234 [==============================] - 13s 54ms/step - loss: 0.5318 - acc: 0.8043 - val_loss: 0.3767 - val_acc: 0.8643\n",
      "Epoch 11/20\n",
      "234/234 [==============================] - 13s 55ms/step - loss: 0.5222 - acc: 0.8071 - val_loss: 0.3862 - val_acc: 0.8635\n",
      "Epoch 12/20\n",
      "234/234 [==============================] - 13s 55ms/step - loss: 0.5069 - acc: 0.8127 - val_loss: 0.3840 - val_acc: 0.8671\n",
      "Epoch 13/20\n",
      "234/234 [==============================] - 13s 54ms/step - loss: 0.5018 - acc: 0.8146 - val_loss: 0.3745 - val_acc: 0.8644\n",
      "Epoch 14/20\n",
      "234/234 [==============================] - 13s 54ms/step - loss: 0.4904 - acc: 0.8184 - val_loss: 0.3740 - val_acc: 0.8682\n",
      "Epoch 15/20\n",
      "234/234 [==============================] - 12s 53ms/step - loss: 0.4867 - acc: 0.8212 - val_loss: 0.4130 - val_acc: 0.8556\n",
      "Epoch 16/20\n",
      "234/234 [==============================] - 13s 56ms/step - loss: 0.4784 - acc: 0.8236 - val_loss: 0.3708 - val_acc: 0.8662\n",
      "Epoch 17/20\n",
      "234/234 [==============================] - 13s 56ms/step - loss: 0.4725 - acc: 0.8270 - val_loss: 0.3800 - val_acc: 0.8696\n",
      "Epoch 18/20\n",
      "234/234 [==============================] - 12s 53ms/step - loss: 0.4676 - acc: 0.8271 - val_loss: 0.3773 - val_acc: 0.8671\n",
      "Epoch 19/20\n",
      "234/234 [==============================] - 13s 54ms/step - loss: 0.4578 - acc: 0.8311 - val_loss: 0.3674 - val_acc: 0.8724\n",
      "Epoch 20/20\n",
      "234/234 [==============================] - 13s 56ms/step - loss: 0.4566 - acc: 0.8309 - val_loss: 0.3494 - val_acc: 0.8792\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f2bab397a90>"
      ]
     },
     "execution_count": 102,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.fit_generator(datagen.flow(x_train, y_train,batch_size=BATCH_SIZE),\n",
    "                    samples_per_epoch=x_train.shape[0],\n",
    "                    nb_epoch=EPOCHS,\n",
    "                    validation_data=(x_test, y_test), callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MwQQW5iOJjwq"
   },
   "source": [
    "###  Report the final train and validation accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1701,
     "status": "ok",
     "timestamp": 1582955910194,
     "user": {
      "displayName": "narayana mantha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBG49VVnVWgC0LuOds0cb1i5wiOhLyqmV5zEUmO2Q=s64",
      "userId": "18079235043046323073"
     },
     "user_tz": -330
    },
    "id": "c1SrtBEPJjwq",
    "outputId": "8070dee2-7e11-4e63-cda1-1db0a026d5a3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 66us/step\n",
      "[0.3494202681541443, 0.8792]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model2.evaluate(x_test, y_test)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4845,
     "status": "ok",
     "timestamp": 1582955917767,
     "user": {
      "displayName": "narayana mantha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBG49VVnVWgC0LuOds0cb1i5wiOhLyqmV5zEUmO2Q=s64",
      "userId": "18079235043046323073"
     },
     "user_tz": -330
    },
    "id": "ZBwVWNQC2qZD",
    "outputId": "45837659-8c3a-459e-e025-f45c2dfb243b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 4s 62us/step\n",
      "[0.3163796895424525, 0.8829]\n"
     ]
    }
   ],
   "source": [
    "loss_and_metrics = model2.evaluate(x_train, y_train)\n",
    "print(loss_and_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8KXqmUDW2rM1"
   },
   "source": [
    "## **DATA AUGMENTATION ON CIFAR10 DATASET**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8mja6OgQ3L18"
   },
   "source": [
    "One of the best ways to improve the performance of a Deep Learning model is to add more data to the training set. Aside from gathering more instances from the wild that are representative of the distinction task, we want to develop a set of methods that enhance the data we already have. There are many ways to augment existing datasets and produce more robust models. In the image domain, these are done to utilize the full power of the convolutional neural network, which is able to capture translational invariance. This translational invariance is what makes image recognition such a difficult task in the first place. You want the dataset to be representative of the many different positions, angles, lightings, and miscellaneous distortions that are of interest to the vision task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6HzVTPUM3WZJ"
   },
   "source": [
    "### **Import neessary libraries for data augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PPM558TX4KMb"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Flatten, Reshape\n",
    "from keras.layers import Convolution2D, MaxPooling2D\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "W6hicLwP4SqY"
   },
   "source": [
    "### **Load CIFAR10 dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NQ1WzrXd4WNk"
   },
   "outputs": [],
   "source": [
    "# Load/Prep the Data\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1194,
     "status": "ok",
     "timestamp": 1582956559826,
     "user": {
      "displayName": "narayana mantha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBG49VVnVWgC0LuOds0cb1i5wiOhLyqmV5zEUmO2Q=s64",
      "userId": "18079235043046323073"
     },
     "user_tz": -330
    },
    "id": "R9Pht1ggHuiT",
    "outputId": "602ebb98-e4df-451c-93f0-43dd0da1cd3c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape =  (50000, 32, 32, 3)\n",
      "x_test shape =  (10000, 32, 32, 3)\n",
      "y_train shape =  (50000, 1)\n",
      "y_test shape =  (10000, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"x_train shape = \", x_train.shape)\n",
    "print(\"x_test shape = \", x_test.shape)\n",
    "print(\"y_train shape = \", y_train.shape)\n",
    "print(\"y_test shape = \", y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1038,
     "status": "ok",
     "timestamp": 1582956564105,
     "user": {
      "displayName": "narayana mantha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBG49VVnVWgC0LuOds0cb1i5wiOhLyqmV5zEUmO2Q=s64",
      "userId": "18079235043046323073"
     },
     "user_tz": -330
    },
    "id": "3n28ccU6Hp6s",
    "outputId": "f836bb5d-9499-4161-cb2b-bb49bc53400d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- THE DATA ---\n",
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "#reshape x_train and x_test data according to input image size\n",
    "x_train = x_train.reshape(x_train.shape[0], 32, 32, 3).astype('float32')\n",
    "x_test = x_test.reshape(x_test.shape[0], 32, 32, 3).astype('float32')\n",
    "\n",
    "#Normalize both the train and test image data from 0-255 to 0-1\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "#Convert train and test labels to one hot vectors\n",
    "y_train = np_utils.to_categorical(y_train, 10)\n",
    "y_test = np_utils.to_categorical(y_test, 10)\n",
    "\n",
    "print('--- THE DATA ---')\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JN3vYYhK4W0u"
   },
   "source": [
    "### **Create a data_gen funtion to genererator with image rotation,shifting image horizontally and vertically with random flip horizontally.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JJbekTKi4cmM"
   },
   "outputs": [],
   "source": [
    "# This will do preprocessing and realtime data augmentation:\n",
    "datagen = ImageDataGenerator(\n",
    "    featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "    samplewise_center=False,  # set each sample mean to 0\n",
    "    featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "    samplewise_std_normalization=False,  # divide each input by its std\n",
    "    zca_whitening=False,  # apply ZCA whitening\n",
    "    rotation_range=50,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "    width_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\n",
    "    height_shift_range=0.2,  # randomly shift images vertically (fraction of total height)\n",
    "    horizontal_flip=True,  # randomly flip images\n",
    "    vertical_flip=True)  # randomly flip images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "e-SLtUhC4dK2"
   },
   "source": [
    "### **Prepare/fit the generator.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CSw8Bv2_4hb0"
   },
   "outputs": [],
   "source": [
    "# Prepare the generator\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gYyF-P8O4jQ8"
   },
   "source": [
    "### **Generate 5 images for 1 of the image of CIFAR10 train dataset.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1244,
     "status": "ok",
     "timestamp": 1582956885681,
     "user": {
      "displayName": "narayana mantha",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AAuE7mBG49VVnVWgC0LuOds0cb1i5wiOhLyqmV5zEUmO2Q=s64",
      "userId": "18079235043046323073"
     },
     "user_tz": -330
    },
    "id": "mXug4z234mwQ",
    "outputId": "ad754630-b3a7-46f3-f656-e47992695f94"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABICAYAAABV5CYrAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/xEB1IuDugG7swAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 5 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "gen = datagen.flow(x_train[0:1], batch_size=1)\n",
    "for i in range(1, 6):\n",
    "    plt.subplot(1,5,i)\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(gen.next().squeeze(), cmap='gray')\n",
    "    plt.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "R7_InternalLab_Questions_FMNIST_Simple_CNN_CIFAR_DATA_Augment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
